---
title: "Applied statistical testing for DM"
author: "Caragea Anda-Maria, Hoisan Stefan-Alexandru"
date: "08/01/2023"
output: slidy_presentation
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(include = TRUE, echo = TRUE)
```

## Cuprins

**1. Distributiile de esantionare**

*1.1 Distributia de esantionare a mediei*

*1.2 Distributia de esantionare a proportiei*

**2. Intervale de incredere**

*2.1 Un interval pentru medie*

*2.2 Un interval pentru proportie*

**3. Componentele unui test de ipoteza**

**4. Testarea mediilor**

*4.1 O singura medie*

*4.2 Doua medii*

**5. Testarea proportiilor**

*5.1 O singura proportie*

*5.2 Doua proportii*

**6. Testarea variabilelor categoriale**

*6.1 O singura variabila categoriala*

*6.2 Doua variabile categoriale*

**7. Erori si Puterea**

*7.1 Erori de testare a ipotezei*

*7.2 Erori de tipul I*

*7.3 Erori de tipul II*

*7.4 Puterea statistica*

**8. One-Way ANOVA**

*8.1 Ipoteze si verificarea diagnosticului*

*8.2 Construirea tabelei prin metoda One-Way ANOVA*

*8.3 Construirea tabelelor ANOVA prin intermediul functiei aov*

**9. Two-Way ANOVA**

*9.1 O suita de ipoteze*

*9.2 Principalele efecte si interactiuni*

**10. Testul Kruskal-Waillis**

## 1. Distributiile de esantionare

#### 1.1 Distributia de esantionare a mediei

-   **Teorema limitei centrale**

Teorema limitei centrale (CLT) afirma ca distributia esantionului se apropie de o distributie normala (cunoscuta si sub numele de „curba clopot") pe masura ce dimensiunea esantionului devine mai mare, presupunand ca toate esantioanele sunt identice ca dimensiune, si indiferent de forma distributiei populatiei.

Sa presupunem ca temperatura maxima zilnica din luna ianuarie in Dunedin, Noua Zeelanda, urmeaza o distributie normala, cu o medie de 22 de grade Celsius si o abatere standard de 1,5 grade. Pentru esantioanele de dimensiunea n = 5, distributia de esantionare a lui x va fi normala, cu media 22 si o eroare standard de 1,5/ √ 5 ≈ 0,671.

```{r}
xvals <- seq(16,28,by=0.1)
fx.samp <- dnorm(xvals,22,1.5/sqrt(5))
plot(xvals,fx.samp,type="l",lty=2,lwd=2,xlab="",ylab="")
abline(h=0,col="gray")
fx <- dnorm(xvals,22,1.5)
lines(xvals,fx,lwd=2)
legend("topright",legend=c("raw obs. distbn.","sampling distbn. (mean)"),
lty=1:2,lwd=c(2,2),bty="n")

#probabilitatea ca o zi din luna ianuarie, aleasa aleatoriu, sa aiba o temperatura maxima de 21,5 grade: 
pnorm(21.5,mean=22,sd=1.5)

#probabilitatea ca media esantionului sa fie mai mica de 21,5 grade, pe baza unui esantion cu 5 zile din ianuarie
pnorm(21.5,mean=22,sd=1.5/sqrt(5))

#Zonele umbrite cu linii arata aceste doua probabilitati. 
abline(v=21.5,col="gray")
xvals.sub <- xvals[xvals<=21.5]
fx.sub <- fx[xvals<=21.5]
fx.samp.sub <- fx.samp[xvals<=21.5]
polygon(cbind(c(21.5,xvals.sub),c(0,fx.sub)),density=10)
polygon(cbind(c(21.5,xvals.sub),c(0,fx.samp.sub)),density=10,
angle=120,lty=2)


```

#### 1.2 Distributia de esantionare a proportiei

Sa presupunem ca o comentatoare din domeniul politic, din Statele Unite ale Americii este interesata de proportia cetatenilor in varsta, din orasul sau natal, care detin capacitatea de a vota si care stiu deja cum vor vota la urmatoarele alegeri prezidentiale. Ea obtine 118 raspunsuri de da sau nu de la 118 indivizi aleatorii. Dintre acesti indivizi, 80 spun ca stiu cum vor vota. Pentru investigarea variabilitatii asociata cu proportia de interes, trebuie luat in considerare ![](formula.png){width="150"}, unde p = 80 / 118 :

```{r}
#estimarea proportiei de interes 
p.hat <- 80/118
p.hat

#aproximarea la distributia normala este valida, deoarece ambele valori sunt mai mari decat 5.  
118*p.hat
118*(1-p.hat)

#estimarea erorii standard 
p.se <- sqrt(p.hat * (1-p.hat) / 118)
p.se

#reprezentarea grafica a distributiei de esantionare:
pvals <- seq(p.hat-5*p.se,p.hat+5*p.se,length=100)
p.samp <- dnorm(pvals,mean=p.hat,sd=p.se)
plot(pvals,p.samp,type="l",xlab="",ylab="",
xlim=p.hat+c(-4,4)*p.se,ylim=c(0,max(p.samp)))
abline(h=0,col="gray")
pvals.sub <- pvals[pvals>=0.7 & pvals<=0.75]
p.samp.sub <- p.samp[pvals>=0.7 & pvals<=0.75]
polygon(cbind(c(0.7,pvals.sub,0.75),c(0,p.samp.sub,0)),
border=NA,col="gray")

#calcularea probabilitatii de interes  
pnorm(0.75,mean=p.hat,sd=p.se) - pnorm(0.7,mean=p.hat,sd=p.se)
```

## 2. Intervale de incredere

#### 2.1 Un interval pentru medie

Revenind la exemplul anterior legat de media zilnica a temperaturii maxime a lunii ianuarie pentru Dunedin, New Zeeland. Sa presupunem ca observatiile sunt distribuite in mod normal, dar nu se cunoaste adevarata medie µX (care este setata la 22) sau adevarata abatere standard (care este stabilita la 1,5).

```{r}
temp.sample <- rnorm(n=5,mean=22,sd=1.5)
temp.sample

#calcularea mediei esantionului, a abaterii standard si a erorii standard corespunzatoare a mediei esantionului 
temp.mean <- mean(temp.sample)
temp.mean
temp.sd <- sd(temp.sample)
temp.sd
temp.se <- temp.sd/sqrt(5)
temp.se


#Valoarea critica (pozitiva) se gaseste prin furnizarea unei probabilitatii de 1 − α/2 = 0,975 a functiei corespunzatoare.

1-0.05/2
critval <- qt(0.975, df = 4)
critval

#aria centrala, simetrica, sub curba, trebuie sa fie 0.95. Se poate confirma acest lucru folosind pt.
pt(critval,4)-pt(-critval,4)

#gasirea intervalului de incredere de 95% pentru adevarata medie, rezultand l si respectiv u, astfel: 
temp.mean-critval*temp.se

temp.mean+critval*temp.se

#un interval de incredere de 80% (α = 0,2) si un interval de incredere de 99% (α = 0,01) pentru aceeasi valoare data: 

temp.mean+c(-1,1)*qt(p=0.9,df=4)*temp.se

temp.mean+c(-1,1)*qt(p=0.995,df=4)*temp.se
```

#### 2.2 Un interval pentru proportie

Stabilirea unui interval de incredere pentru o proportie a unui esantion urmeaza aceleasi reguli ca si pentru medie. Pentru estimarea p dintr-un esantion de marime n, intervalul insusi este construit cu eroarea standard ![](formula2.png).

Revenind la exemplul anterior, in care 80 din 118 persoane intervievate au spus ca stiu cum vor vota la urmatoarele alegeri prezidentiale din SUA:

```{r}
p.hat <- 80/118
p.hat
p.se <- sqrt(p.hat*(1-p.hat)/118)
p.se

#pentru a construi un interval de incredere de 90 % (α = 0,1), valoarea critica adecvata din distributia de esantionare standardizata de interes este dupa cum urmeaza, implicand Pr(−1,644854 < Z < 1,644854) = 0,9 pentru Z ∼ N(0,1):

qnorm(0.95)

#putem concluziona, in proportie de 90%, ca proportia reala de alegatori care stiu cum vor vota la urmatoarele alegeri se afla intre 0,61 si 0,75.

p.hat + c(-1,1) * qnorm(0.95)*p.se


```

## 3. Componentele unui test de ipoteza

Testarea ipotezei este o procedura statistica in care se alege intre o ipoteza nula si o ipoteza alternativa bazate pe informatiile dintr-un esantion. Componentele unui test sunt:

### - Ipoteze

**Ipoteza nula**, notata H0

**Ipoteza alternativa**, notata Ha

### - Test Statistic

### - p-value

### - Nivel de semnificatie

## 4. Testarea mediilor

#### 4.1 O singura medie - Testul T cu un esantion

Un producator de snacks-uri este interesat de greutatea neta medie a continutului dintr-un pachet de 80 de grame. Un consumator suna si depune o plangere - de-a lungul timpului a cumparat si a cantarit exact continutul a 44 de pachete de 80 de grame alese aleatoriu din diferite magazine si a inregistrat greutatile astfel:

```{r}
 snacks <- c(87.7,80.01,77.28,78.76,81.52,74.2,80.71,79.5,77.87,81.94,80.7,
82.32,75.78,80.19,83.91,79.4,77.52,77.62,81.4,74.89,82.95,
73.59,77.92,77.18,79.83,81.23,79.28,78.44,79.01,80.47,76.23,
78.89,77.14,69.94,78.54,79.7,82.45,77.29,75.52,77.21,75.99,
81.94,80.41,77.7)

#Clientul sustine ca datele nu pot fi provenite dintr-o distributie cu media µ = 80, deci media adevărată greutatea trebuie să fie mai mică de 80.

#se definesc ipotezele astfel: H0: µ = 80 si Ha: µ < 80
#se calculeaza media si abaterea standard a esantionului

n <- length(snacks)
snack.mean <- mean(snacks)
snack.mean
snack.sd <- sd(snacks)
snack.sd

#se calculeaza testul statistic, primul pas fiind calcularea erorii standard a esantionului pentru datele din snacks

snack.se <- snack.sd/sqrt(n)
snack.se

#apoi se calculeaza T: 

snack.T <- (snack.mean-80)/snack.se
snack.T

#testul statistic este utilizat pentru a obtine p, asadar:
#deoarece p este mai mic decat α = 0,05, exista suficiente dovezi pentru a respinge ipoteza nula

pt(snack.T, df = n-1)


#rezultatul testului T cu un esantion poate fi gasit si cu functia t.test
t.test(x=snacks,mu=80,alternative="less")

```

#### 4.2 Doua medii

#### Esantioane independente, cu dispersii diferite

Pentru un exemplu de esantioane independente, cu disperii diferite, revenim la exemplul cu pachetul de snacks-uri de 80 de grame. Dupa colectarea unui esantion de 44 de pachete (marime notata cu n1). Consumatorul nemultumit colecteaza n2 = 31 pachete de 80 de grame alese aleatoriu de la un producator rival de snacks-uri. Acest set de date se stocheaza in snacks2.

```{r}
snacks2 <- c(80.22,79.73,81.1,78.76,82.03,81.66,80.97,81.32,80.12,78.98,
79.21,81.48,79.86,81.06,77.96,80.73,80.34,80.01,81.82,79.3,
79.08,79.47,78.98,80.87,82.24,77.22,80.03,79.2,80.95,79.17,81)


#calcularea mediei si a abaterii standard pentru al doilea esantion 

snack2.mean <- mean(snacks2)
snack2.mean
snack2.sd <- sd(snacks2)
snack2.sd

#adevarata media a noului esantion este notat cu µ2. Se construiesc ipotezele astfel: 
#H0 : µ2 − µ1 = 0

#HA : µ2 − µ1 > 0 

#efectuarea testului cu alternative="greater", snacks2 sunt cele furnizate lui x: 

t.test(x=snacks2,y=snacks,alternative="greater",conf.level=0.9)

#se poate interpreta astfel: „90 % increzator ca adevarata diferenta intre greutatea medie neta dintre rival si producatorul original este undeva intre 0,395 si 2,098 grame.

(snack2.mean-snack.mean) + c(-1,1)*qt(0.95,df=60)*sqrt(snack.sd^2/44+snack2.sd^2/31)

```

#### Esantioane independente, cu dispersii egale

Sa presupunem, in mod rezonabil, ca scorurile IQ sunt distribuite in mod normal, iar IQ-ul mediu al populatiei este de 100. Ne intereseaza sa evaluam daca exista o diferenta intre media IQ-ului dintre barbati si femei, sugerand urmatoarele ipoteze: nmen = 12 si nwomen = 20: H0: µmen - µwomen = 0 Ha: µmen - µwomen != 0

```{r}
men <- c(102,87,101,96,107,101,91,85,108,67,85,82)
women <- c(73,81,111,109,143,95,92,120,93,89,119,79,90,126,62,92,77,106,
105,111)
#se calculeaza media si abaterea standard a esantioanelor
mean(men)
sd(men)
mean(women)
sd(women)

#raportul abaterilor standard:
sd(women)/sd(men)

#Testul T

t.test(x=men,y=women,alternative="two.sided",conf.level=0.95,var.equal=TRUE)
```

#### Esantioane pereche

Se ia in considerare o companie interesata de eficacitatea unui medicament conceput pentru a reduce frecventa cardiaca in repaus in batai pe minut (bpm). Este masurata frecventa cardiaca de repaus a 16 indivizii.Indivizilor li se administreaza apoi un tratament si li se masoara din nou ritmul cardiac de repaus. Datele sunt furnizate in cei doi vectori rate.before si rate.after:

```{r}
rate.before <- c(52,66,89,87,89,72,66,65,49,62,70,52,75,63,65,61)
rate.after <- c(51,66,71,73,70,68,60,51,40,57,65,53,64,56,60,59)

#Testul T cu doua esantioane pereche ia in considerare diferenta dintre fiecare pereche de valori. 

rate.d <- rate.after-rate.before
rate.d

#este calculata media esantionului si abaterea standard a acestor diferente:
rate.dbar <- mean(rate.d)
rate.dbar
rate.sd <- sd(rate.d)
rate.sd

#vrem sa vedem cu cat se reduce ritmul cardiac, asa ca testul va avea urmatoarele ipoteze: 
#H0 : µd = 0

#Ha : µd < 0 

#oentru exemplele actuale de ipoteze, se poate gasi statistica testului si valoarea p cu rate.dbar si rate.sd
rate.T <- rate.dbar/(rate.sd/sqrt(16))
rate.T
pt(rate.T, df = 15)

#aceste rezultate sugereaza dovezi pentru respingerea H0.
t.test(x=rate.after,y=rate.before,alternative="less",conf.level=0.95,
paired=TRUE)

#putem spune ca suntem 95% increzatori ca adevarata diferenta medie a frecventei cardiace dupa administrarea tratamentului se afla undeva intre
rate.dbar-qt(0.975,df=15)*(rate.sd/sqrt(16))

#si
rate.dbar+qt(0.975,df=15)*(rate.sd/sqrt(16))
```

## 5. Testarea proportiilor

#### 5.1 O singura proportie - Testul Z cu un esantion

Sa presupunem ca o persoana care prefera un anumit lant de fast-food tinde sa aiba stomacul deranjant intr-un anumit interval de timp dupa ce a luat pranzul obisnuit. El gaseste site-ul unui blogger care crede ca exista sansa de 20% de a avea probleme la stomac la scurt timp dupa ce s-a mancat alimentul repsectiv. Individul este curios sa determine daca rata reala a problemelor la stomac este diferita de valoarea citata de blogger si, de-a lungul timpului, viziteaza aceste magazine de tip fast-food in n = 29 ocazii separate, inregistrand succesul sau esecul de a experimenta probleme cu stomacul. Asadar sunt formulate urmatoarele ipoteze: **H0: π = 0.2**

**Ha : π != 0.2**

Acestea sunt datele observate, unde 1 semnifica atunci cand a avut probleme cu stomacul si 0 in caz contrar:

```{r}
sick <- c(0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,1,1,1,0,0,0,1)

#numarul de succese si probabilitatea de succes din acest esantion:
sum(sick)
p.hat <- mean(sick)
p.hat

#o verificare rapida indica faptul ca, conform regulii generale, testul poate fi efectuat in mod rezonabil

29*0.2
29*0.8

#statistica in z-Test pentru acest exemplu: 

Z <- (p.hat-0.2)/sqrt(0.2*0.8/29)
Z

2*(1-pnorm(Z))

#
 p.hat+c(-1,1)*qnorm(0.975)*sqrt(p.hat*(1-p.hat)/29)

#se calculeaza intervalul de incredere la un nivel de 95%
 
 p.hat+c(-1,1)*qnorm(0.975)*sqrt(p.hat*(1-p.hat)/29)

```

**Functia prop.test**

```{r}
 prop.test(x=sum(sick),n=length(sick),p=0.2,correct=FALSE)

```

#### 5.2 Doua proportii - Testul Z cu 2 esantioane

Se ia in considerare un grup de studenti care sustin un examen de statistica. In aceasta grupa sunt n1 = 233 studenti cu specializare in psihologie, dintre care x1 = 180 trec si n2 = 197 studenti cu specializare in geografie, dintre care 175 trec. Sa presupunem ca se pretinde ca studentii la geografie au o rata de promovare mai mare decat cei de la psihologie. Reprezentand adevaratele rate de promovare pentru studentii la psihologie ca π1 si studentii la georafie ca π2, aceasta afirmatie poate fi testata statistic folosind o pereche de ipoteze: **H0: π2 − π1 = 0**

**Ha : π2 − π1 \> 0**

Se pot evalua cantitatile necesare ca atare:

```{r}
x1 <- 180
n1 <- 233
p.hat1 <- x1/n1
p.hat1
x2 <- 175
n2 <- 197
p.hat2 <- x2/n2
p.hat2

#proportia comuna
p.star <- (x1+x2)/(n1+n2)
p.star

#calculare test Z
Z <- (p.hat2-p.hat1)/sqrt(p.star*(1-p.star)*(1/n1+1/n2))
Z

#valoare p substantial mai mica decat α, deci se respinge ipoteza nula in favoarea celei alternative

1-pnorm(Z)
```

**Functia prop.test**

```{r}
prop.test(x=c(x2,x1),n=c(n2,n1),alternative="greater",correct=FALSE)
```

## 6. Testarea variabilelor categoriale

#### 6.1 O singura variabila categoriala

-   *Functia chisq.test primeste vectorul de frecvente ca prim argument x*

```{r, eval=TRUE}
hairy <- c(2,3,2,3,2,1,3,3,2,2,3,2,2,2,3,3,3,2,3,2,2,2,1,3,2,2,2,1,2,2,3,
2,2,2,2,1,2,1,1,1,2,2,2,3,1,2,1,2,1,2,1,3,3)
hairy.tab <- table(hairy)
# H0 : π1 = π2 = π3 = 1/3
# HA : H0 este incorect

# Functia chisq.test efectueaza un test chi-patrat de distributie
# Se tine cont de distributia observata si cea teoretica
chisq.test(x=hairy.tab)
# Valoarea p-value este mica (< 0.01) -> Ipoteza H0 este respinsa
# Proportiile nu sunt egale
```

-   *In cazul in care nu se doreste un test de uniformitate - probabilitatile nu sunt uniforme*

```{r, eval=TRUE}
# H0 : π0(1) = 0,25; π0(2) = 0,5; π0(3) = 0,25
# HA : H0 este incorect.
chisq.test(x=hairy.tab,p=c(0.25,0.5,0.25))
# Valoarea p-value este mare (> 0.5) -> Ipoteza H0 este acceptata
```

#### 6.2 Doua variabile categoriale

-   *Functia chisq.test primeste matricea cu valorile pentru cele 2 variabile*

```{r, eval=TRUE}
skin <- matrix(c(20,32,8,52,9,72,8,32,16,64,30,12),4,3,
dimnames=list(c("Injection","Tablet","Laser","Herbal"),
c("None","Partial","Full")))
# Notam cele doua variabile categoriale cu A si B si pornim de la ipotezele:
# H0 : Variabilele A și B sunt independente (nu există nicio relație între A și B)
# HA : Variabilele A și B nu sunt independente (există o relație între A și B)

# Functia chisq.test efectueaza un test chi-patrat de independenta
# Se tine cont de frecventele liniilor si coloanelor
chisq.test(x=skin)
# Valoarea p-value este extrem de mica, avem dovezi clare pentru respingerea H0
```

## 7. Erori si Puterea

#### 7.1 Erori de testare a ipotezei

-   *Eroarea de tipul I are loc atunci cand se respinge in mod incorect o afirmatie H0 adevarata. In oricare ipoteza de testare, probabilitatea de aparitie a unei Erori de tipul I este echivalenta cu nivelul de significanta α.*

-   *Eroarea de tipul II are loc atunci cand se accepta in mod incorect o afirmatie H0 falsa. De vreme ce depinde de valoarea de adevar a lui HA, probabilitatea de aparitiei unei astfel de erori, denumita β, nu este cunoscuta in practica.*

#### 7.2 Erori de tipul I

-   *Daca p-value este mai mica decat α, se respinge afirmatia nula. Daca H0 este de fapt adevarata, valoarea lui α defineste in mod direct probabilitatea faptului ca afirmatia a fost incorect respinsa. Acest fenomen este definit ca o eroare de tipul I.*

-   *Functia typeI.tester genereaza un numar de probe egal cu valoarea variabilei ITERATIONS dintr-o distributie normala particulara. Cu fiecare proba, se produce un test de medie de tip coada superioara, presupunand ipotezele*

**H0 : µ = µ0**

**HA : µ \> µ0**

```{r, eval=TRUE}
iterations<-10000
typeI.tester <- function(mu0,sigma,n,alpha,ITERATIONS=iterations){
  pvals <- rep(NA,ITERATIONS)
  for(i in 1:ITERATIONS){
    temporary.sample <- rnorm(n=n,mean=mu0,sd=sigma)
    temporary.mean <- mean(temporary.sample)
    temporary.sd <- sd(temporary.sample)
    pvals[i] <- 1-pt((temporary.mean-mu0)/(temporary.sd/sqrt(n)),df=n-1)
  }
  return(mean(pvals<alpha))
}

value<-typeI.tester(mu0=0,sigma=1,n=40,alpha=0.05)
value
# Numarul de probe ce vor duce la respingerea incorecta a lui H0:
value*iterations

typeI.tester(mu0=-4,sigma=0.3,n=60,alpha=0.01)
```

#### 7.3 Erori de tipul II

-   *O eroare de tip II se refera la retinerea in mod incorect a ipotezei nule -- cu alte cuvinte, obtinerea unui p-value mai mare decat significantul de nivel cand ipoteza alternativa este cea adevarata. Probabilitatea de aparitie a unei Erori de Tip II se noteaza cu β*

**H0 : µ = µ0**

**HA : µ \> µ0, µ0 = 0**

```{r, eval=TRUE}
iterations<-10000
typeII.tester <- function(mu0,muA,sigma,n,alpha,ITERATIONS=iterations){
  pvals <- rep(NA,ITERATIONS)
  for(i in 1:ITERATIONS){
    temporary.sample <- rnorm(n=n,mean=muA,sd=sigma)
    temporary.mean <- mean(temporary.sample)
    temporary.sd <- sd(temporary.sample)
    pvals[i] <- 1-pt((temporary.mean-mu0)/(temporary.sd/sqrt(n)),df=n-1)
  }
  return(mean(pvals>=alpha))
}

value<-typeII.tester(mu0=0,muA=0.5,sigma=1,n=30,alpha=0.05)
# Sansa de a retine incorect ipoteza nula:
value * 100
# (In procente)

value2<-typeII.tester(mu0=0,muA=0.5,sigma=1,n=30,alpha=0.01)
# Sansa de a retine incorect ipoteza nula, dupa schimbarea valorii alpha:
value2 * 100
# (In procente)
```

#### 7.4 Puterea statistica

-   *Prin conventie, un test de ipoteză care are o putere mai mare de 0,8 este considerat puternic din punct de vedere statistic.*

-   *Puterea este probabilitatea de a respinge corect o ipoteza nula care nu este adevarata.*

-   *Pentru un test care are o rata de eroare de Tip II egala cu β, puterea statistica este egala cu 1 - β.*

```{r, eval=TRUE}
# Functia simuleaza puterea fiecarei marimi de esationare
# Puterile calculate sunt stocate intr-un vector rezultat care este intors de functie.
power.tester <- function(nvec,...){
  nlen <- length(nvec)
  result <- rep(NA,nlen)
  for(i in 1:nlen){
    result[i] <- 1-typeII.tester(n=nvec[i],...)
  }
  return(result)
}

sample.sizes <- 5:100
# Rularea functiei pe dimensiunile de esantionare generate, folosind un numar de iteratii egal cu 5000:
pow <- power.tester(nvec=sample.sizes,
mu0=0,muA=0.6,sigma=1.2,alpha=0.01,ITERATIONS=5000)
# Identificarea gradului de esantionare minim necesar atingerii pragului de putere (80%)
minimum.n <- sample.sizes[min(which(pow>=0.8))]
pow[minimum.n]
minimum.n
```

## 8. One-Way ANOVA

-   *Analiza variantei (ANOVA) este o metoda statistica utilizata pentru a testa daca exista o diferența semnificativa intre mediile mai multor grupuri.*

-   *ANOVA permite compararea mai multor grupuri simultan si determina daca exista cel putin o diferenta intre ele.*

#### 8.1 Ipoteze si verificarea diagnosticului

Urmatoarele presupuneri trebuie validate pentru ca rezultatele unui test ANOVA One-Way sa fie de incredere:

-   **Independenta** - Datele din cele k grupuri trebuie sa fie independente intre ele si observatiile din fiecare grup trebuie sa fie independente si identic distribuite.
-   **Normalitatea** - Observatiile din fiecare grup ar trebui sa fie normal distribuite sau cel putin sa fie aproximativ normal distribuite.
-   **Egalitatea variatiilor** - Variatia observatiilor din fiecare grup ar trebui sa fie egala sau cel putin aproximativ egala.

**Egalitatea variatiilor:**

**H0 : μcasein = μhorsebean = µlinseed = µmeatmeal = µsoybean = µsunflower**

**HA : Mediile nu sunt toate egale.**

```{r, eval=TRUE}
# Obtinerea variatiilor standard in functie de tipul de hrana
chick.sds <- tapply(chickwts$weight,INDEX=chickwts$feed,FUN=sd)

# Raportul dintre variatia standard maxima si cea minima < 2
# Deci H0 este acceptata
max(chick.sds)/min(chick.sds)
```

**Normalitatea:**

```{r, eval=TRUE}
# Se va calcula vectorul mediilor centrate
chick.means <- tapply(chickwts$weight,INDEX=chickwts$feed,FUN=mean)
chick.meancen <- chickwts$weight-chick.means[as.numeric(chickwts$feed)]
# Se realizeaza graficul QQ normal al reziduurilor
qqnorm(chick.meancen,main="Grafic QQ normal al reziduurilor")
qqline(chick.meancen)
# Se poate observa din grafic ipoteza de normalitate a datelor
```

#### 8.2 Construirea tabelei prin metoda One-Way ANOVA

Testul continua prin a calcula intai metricile asociate cu variabilitatea generala si apoi calculul variabilitatii din grupuri si dintre grupuri. Toate acestea culmineaza printr-un singur test statistic si incadrarea p-value in ipoteza mentionata anterior. Aceste valori sunt definite de obicei intr-un tabel, dupa cum urmeaza:

-   *xi - xN reprezinta N observatii, indiferent de grup*

-   *xi(j) - xn(j) reprezinta observatiile dintr-un anumit grup j = 1...k, astfel incat n1 + ... + nk = N.*

-   *x̅ reprezinta marea medie a observatiilor este definita ca fiind media aritmetica a observatiilor*

-   Tabelul ANOVA este apoi construit, notarile avand urmatoarea definitie:

SS - suma patratelor; df - grade de libertate; MS - media patrata; F - statistica testului F; p - p-value

<center>![](Part2/tabel-anova.PNG)</center>

#### 8.3 Construirea tabelelor ANOVA prin intermediul functiei aov

R permite construirea usoara a unui tabel ANOVA folosind functia predefinita aov:

```{r, eval=TRUE}
chick.anova <- aov(weight~feed,data=chickwts)
summary(chick.anova)
# Aceste rezultate se pot confirma folosind ecuatiile expuse mai devreme
# O valoare mica a p-value desemneaza respingerea ipotezei nule H0
```

## 9. Two-Way ANOVA

-   *Creșterea numărului de variabile de grupare complică lucrurile*

-   *Efectuarea ANOVA cu un singur factor pentru fiecare variabilă în parte este inadecvată*

-   *Cand se trateaza un caz cu mai mult de un factor de grupare categorica, trebuie să luam în considerare efectele principale ale fiecărui factor asupra rezultatului numeric*

#### 9.1 O suita de ipoteze

-   Inainte de a enunta ipotezele, vom nota variabila numerica de rezultat cu **O** si cele doua variabile de grupare cu **G1** si **G2**. Ipotezele pentru ANOVA cu doi factori de grupare sunt urmatoarele:

**H0 :**

  **- G1 nu are niciun efect principal (marginal) asupra mediei lui O.**

  **- G2 nu are un efect principal (marginal) asupra mediei lui O.**

  **- Nu există niciun efect interactiv al lui G1 cu G2 asupra mediei lui O.**

**HA : Separat, fiecare afirmație din H0 este incorectă.**

```{r, eval=TRUE}
# Funcția aggregate este similară cu tapply, dar returnează un dataframe
# Primul argument primește vectorul de date interes.
# Al doilea argument, by, trebuie să fie o listă cu variabilele de grupare dorite
# In FUN se specifică funcția care trebuie să opereze asupra fiecărui subset
wb.means <- aggregate(warpbreaks$breaks, by=list(warpbreaks$wool,warpbreaks$tension),FUN=mean)
wb.means
```

#### 9.2 Principalele efecte si interactiuni

Pentru a ține cont de interacțiuni, se face o ușoară ajustare a modelului ANOVA cu doi factori:

```{r, eval=TRUE}
summary(aov(breaks~wool+tension+wool:tension,data=warpbreaks))
```

Putem interpreta mai detaliat un efect de interactiune a doi factori folosind functia interaction.plot:

```{r, eval=TRUE}
interaction.plot(x.factor=wb.means[,2],trace.factor=wb.means[,1],
  response=wb.means$x,trace.label="wool",
  xlab="tension",ylab="mean warp breaks")
```

## 10. Testul Kruskal-Wallis

-   *Cand comparam mai multe medii, exista situatii in care nu vrem sa presupunem normalitatea sau constatam ca presupunerea normalitatii nu este valabila in cadrul verificarilor de diagnosticare*

-   *In acest caz, se va folosi testul Kruskal Wallis, o alternativa a metodei ANOVA cu un singur factor care relaxeaza dependenta de necesitatea normalitatii*

-   *Ipotezele pentru acest test sunt urmatoarele:*

  **H0 : Medianele grupurilor sunt toate egale**

  **HA : Medianele grupurilor nu sunt toate egale (alternativ, cel puțin o mediană de grup diferă)**

```{r, eval=TRUE}
library("MASS")
boxplot(Age~Smoke,data=survey)

age.means <- tapply(survey$Age,survey$Smoke,mean)
age.meancen <- survey$Age-age.means[as.numeric(survey$Smoke)]
qqnorm(age.meancen,main="Normal QQ plot of residuals")
qqline(age.meancen)

# Cu această posibila incalcare a normalitatii, putem aplica testul Kruskal-Wallis in loc de ANOVA
# O verificare rapida pentru egalitatea varianțelor sustine si mai mult acest lucru
# Raportul dintre cea mai mare si cea mai mica deviatie standard fiind in mod clar mai mic decat 2:
survey.sds<-tapply(survey$Age,survey$Smoke,sd)
max(survey.sds)/min(survey.sds)

# Un test Kruskal-Wallis este efectuat folosind functia kruskal.test:
kruskal.test(Age~Smoke,data=survey)

# Valorile mari ale p-value sugereaza ca ipoteza H0 nu este incalcata
# Deci, nu pare sa existe o diferenta intre medianele varstelor studentilor
```

## Exercitiul 1

<center>![](Exercise%2017.1.png)</center>

```{r}
#Exercitiul 1

mean <- 41.1
sd <- 11.3
n <- 6

#a 
se <- sd / sqrt(n)
se

#b
pnorm(55, mean, se) - pnorm (45, mean, se)

#c
pnorm(65/2, mean, se)


#Exericitul 2
n <- 140
p <- 0.35 #probabilitatea ca A sa fie ales

#d 
p * n >= 5 & n * (1 - p) >= 5

#e
se <- sqrt(p * (1-p) / n )
1 - pnorm(0.4, p, se)

#f
upper <- qnorm(0.9, p , se)
lower <- qnorm(0.1, p, se)

#Exercitiul 3

n <- 63
xmean <- 37.8
s <- 34.51

#g 
se <- s/sqrt(n)
df <- n - 1

#i 
newx <- (40 - xmean) / se
1 - pt(newx, df)

#ii
newx <- (30 - xmean) / se
pt(newx, df)

#iii
newx <- (40 - xmean) / se
pt(newx, df) - 0.5
```

## Exercitiul 2

<center>![](Exercise%2017.2.1.png)</center>

<center>![](Exercise%2017.2.2.png)</center>

```{r}

n=34
x.bar<-14.22
sigma<-2.9

#a. construirea si interpretarea unui interval de incredere de 90% pentru timpul mediu adevarat
alpha<-1-.9
x.bar+c(-1,1)*qnorm(1-alpha/2)*(sigma/sqrt(n))

#b. 
s<-2.9
x.bar+c(-1,1)*qt(1-alpha/2,df=n-1)*(s/sqrt(n))

n<-400
#optiunea B = stangaci
p.b<-37/n
p.b
#optiunea C = ambidextri
p.c<-11/n
p.c
#optiunea A = dreptaci
p.a<-1-p.b-p.c
p.a


#c. calcularea unui IC de 99% pentru proportia reala de cetateni care sunt B

alpha<-1-0.99
p.b+(c(-1,1)*qnorm(1-alpha/2))*sqrt(p.b*(1-p.b)/n)


#d. 99% încredere in IC a proportiei realea cetatenilor stangaci sau ambidextri

(p.b + p.c)+ c(-1, 1) * qnorm(1 - alpha / 2) * (sqrt((p.b + p.c) * (1 - (p.b + p.c)) / n))

#e.

x.mat<-matrix(NA,5000,3)
n<-300
lambda<-0.1
mu<-1/lambda

for(i in 1: nrow(x.mat)) {
  sample <- rexp(n, lambda)
  limits <- mean(sample) + c(-1,1) * qt(1-0.05/2, df = n-1) * (sd(sample) / sqrt(n))
  x.mat[i, 1:2] <- limits
  x.mat[i, 3] <- mu >= limits[1]&mu<=limits[2]
}
mean(x.mat[,3])

#reprezentarea grafica a primelor 100 intervale de incredere cu media la mijloc

xaxis<-seq(mu-3,mu+3,length=100)
yaxis<-1:100

plot(xaxis, yaxis, type = "n") + abline(v = 10, lty = 2) + for (i in 1:length(xaxis)) {
lines(c(x.mat[i, 1], x.mat[i, 2]), c(i, i), col = if (x.mat[i, 1] < 10 & x.mat[i, 2] > 10) {
                        "blue"
                  } else{
                        "red"
                  })
            
            
            
      }

     
```

## Exercitiul 3

<center>![](Exercise%2018.1.png)</center>

```{r, eval = TRUE}
#a. 

mu<-3.5

n<-73
x.bar<-3.97
x.sd<-2.21
#semnificatie = 0.05
#H0<- 3.35
#Ha != H0

#probabilitatea este mai mare decat alfa (valoarea semnificatiei). Asadar, nu avem motive sa credem ca ipoteza H0 nu este adevarata.

t<-(x.bar-mu)/(x.sd/sqrt(n))
t
p<-pt(-t,df=n-1)+(1-pt(t,df=n-1))
p

#Intervalul de incredere contine H0
IC<- x.bar+c(-1,1)*qt(0.975,n-1)*x.sd/sqrt(n)
IC

#b. 
#magnitudinea medie a evenimentelor seismice din Fiji
mu <- 4.3

# Ha > H0
alpha <- 0.01
remove(x.bar)

#valoare p este prea mica - dovada puternica - adevarata magnitudine e mai mare decat 4,3

t.test(quakes$mag,mu=mu,alternative="greater",conf.level=1-alpha)

#c. 
#Intervalul de incredere nu contine media H0 pentru adevarata valoare a mediei 
n<-length(quakes$mag)
n
IC<-mean(quakes$mag)+ c(-1,1)*qt(1-0.01/2,n-1)* sd(quakes$mag)/sqrt(n)
IC
```

## Exercitiul 4

<center>![](Exercise%2018.2.1.png)</center>

<center>![](Exercise%2018.2.2.png)</center>

```{r, eval = TRUE}
#a. 

library("MASS")

anorexia 
alpha <- 0.05
#H0: d.mu=0 // Ha: d.mu>0 

#Valoarea lui p este mica, ceea ce indica dovezi puternice pentru acceptarea H0.
t.test(anorexia[,3],
       anorexia[,2],
       alternative = "greater",
       paired=TRUE)



#b.
#Cont
#Nu exista dovezi statistice care sa respinga afirmatia ca nu exista diferente intre media pre si post in grupul de control.
t.test(anorexia[anorexia$Treat=="Cont",3],
       anorexia[anorexia$Treat=="Cont",2],
       alternative="greater",
       paired=TRUE)

#CBT
#Exista dovezi statistice pentru a accepta ca media post este mai mare decat media pre in grupul CBT.
t.test(anorexia[anorexia$Treat=="CBT",3],
       anorexia[anorexia$Treat=="CBT",2],
       alternative="greater",
       paired=TRUE)

#FT
#Exista dovezi statistice puternice pentru a accepta ca in grupul FT media post este mai mare decat media pre
t.test(anorexia[anorexia$Treat=="FT",3],
       anorexia[anorexia$Treat=="FT",2],
       alternative="greater",
       paired=TRUE)

#c.
#Ipoteze -> H0: ctrlmean - trtmean = 0 // Ha: ctrlmean - trtmean < 0
head(PlantGrowth)
levels(PlantGrowth[, 2])
data.1 <- PlantGrowth[PlantGrowth$group == "ctrl", ]
data.2 <- PlantGrowth[PlantGrowth$group != "ctrl", ]

#Regula de baza - exista suficiente dovezi pentru a accepta ambele variante, se folosoeste testul de estimare a variantei cumulate

sd(PlantGrowth[PlantGrowth$group != "ctrl",1])/
      sd(PlantGrowth[PlantGrowth$group == "ctrl",1])

#d.
#Valoarea p ~ 0,41 - nu exista dovezi pentru a respinge H0, deoarece este mai mare decat alpha = 0,05. Nu exista dovezi statistice suficiente ca trtmean sa fie mai mare decat ctrlmean.

t.test(PlantGrowth[PlantGrowth$group == "ctrl", 1],
       PlantGrowth[PlantGrowth$group != "ctrl", 1],
       alternative="less",
       var.equal = TRUE)
#e.
my.t.test <- function(x,
                      y,
                      var.equal = FALSE,
                      paired = FALSE,
                      ...) {
      if (!paired) {
            var.equal <- max(c(sd(x), sd(y))) /
                  min(c(sd(x), sd(y))) < 2
      }
      return(t.test(
            x = x,
            y = y,
            var.equal = var.equal,
            paired = paired,
            ...
      ))
}


my.t.test2 <- function(x,
                      y,
                      var.equal = FALSE,
                      paired = FALSE,
                      ...) {
      if (paired) {
            var.equal <- max(c(sd(x), sd(y))) /
                  min(c(sd(x), sd(y))) < 2
      }
      return(t.test(
            x = x,
            y = y,
            var.equal = var.equal,
            paired = paired,
            ...
      ))
}

#f.

#i.
snacks <- c(87.7,80.01,77.28,78.76,81.52,74.2,80.71,79.5,77.87,81.94,80.7,82.32,
            75.78,80.19,83.91,79.4,77.52,77.62,81.4,74.89,82.95,73.59,77.92,77.18,
            79.83,81.23,79.28,78.44,79.01,80.47,76.23,78.89,77.14,69.94,78.54,79.7,
            82.45,77.29,75.52,77.21,75.99,81.94,80.41,77.7)
snacks2 <- c(80.22,79.73,81.1,78.76,82.03,81.66,80.97,81.32,80.12,78.98,79.21,
             81.48,79.86,81.06,77.96,80.73,80.34,80.01,81.82,79.3,79.08,79.47,
             78.98,80.87,82.24,77.22,80.03,79.2,80.95,79.17,81)
my.t.test(snacks2,snacks,alternative="greater")

#ii.

men <- c(102,87,101,96,107,101,91,85,108,67,85,82)
women <- c(73,81,111,109,143,95,92,120,93,89,119,79,90,126,62,92,77,106,105,111)

my.t.test(men,women,alternative="two.sided")

#iii.

rate.before <- c(52,66,89,87,89,72,66,65,49,62,70,52,75,63,65,61) 
rate.after <- c(51,66,71,73,70,68,60,51,40,57,65,53,64,56,60,59) 

my.t.test(rate.after,rate.before,alternative="less",paired=TRUE)
```

## Exercitiul 5

<center>![](Exercise%2018.3.png)</center>

```{r}
#a. 
#Ipoteze: H0: p=0.9 // Ha: p <0.9
#intrucat ambele sunt adevarate, putem accepta sa se efectueze cu o distributie normala

p<-0.9
n<-89
x<-71
p.hat<-x/n
n*p.hat>5&n*(1-p.hat)>5



#b. 

#valoarea p este prea mica, exista destule dovezi statistice pentru a respinge H0 in favoarea Ha.
z.test<-(p.hat-p)/(sqrt(p*(1-p)/n))
pnorm(z.test)



#c. CI

#se exclude media pretinsa de 0.9

p.hat+c(-1,1)*qnorm(0.99)*sqrt(p*(1-p)/n)

x1<-97
n1<-445
x2<-90
n2<-419

p.hat1<-x1/n1
p.hat2<-x2/n2

#d.
alpha<-0.05
#Ipoteze: H0 : p2-p1 = 0 // Ha: p2-p1 != 0

#valoarea p este una mare. Nu exista suficiente dovezi statistice ca probabilitatea este diferita in fiecare tara -> varianta cumulata

prop.test(c(x2,x1),c(n2,n1),alternative = "two.sided",conf.level = 1-alpha, correct = FALSE)


p<-(x1+x2)/(n1+n2)
p

#testarea cu calculul manual
z<-(p.hat2-p.hat1)/(sqrt(p*(1-p)*(1/n1+1/n2)))
z
pval<-2*pnorm(z)
pval

#e. crearea intervalului de incredere statistic + cricital Value*SE

#Intervalul de incredere include valoarea 0, asigurand ca ambele state ar putea avea aceeasi proportie.

se<-sqrt(p*(1-p)*(1/n1+1/n2))
(p.hat2-p.hat1)+c(-1,1)*qnorm(1-alpha/2)*se

```

## Exercitiul 6

<center>![](Part2/Exercise%2018.4-final.png)</center>

```{r, eval=FALSE}
# a

data(HairEyeColor)
total.hec<-HairEyeColor[,,1]+HairEyeColor[,,2]

chisq.test(total.hec)

# Avem o valoare foarte mica a lui p-value
# Deci avem dovezi statistice puternice pentru a respinge ipoteza H0
# Ceea ce inseamna ca variabilele A si B nu sunt independente

# b

library("car")
Duncan[,1]

c.prof<-length(Duncan[Duncan[,1]=="prof",1])
c.bc<-length(Duncan[Duncan[,1]=="bc",1])
c.wc<-length(Duncan[Duncan[,1]=="wc",1])

Duncan.tab<-table(Duncan[,1])

# Ipotezele: H0: p1=p2=p3=1 
# Ha: H0 este gresit

chisq.test(Duncan.tab)

# i

# Valoarea lui p-value este mai mica decat alpha = 0.05, ceea ce respinge ipoteza H0
# Putem afirma faptul ca variabilele A si B sunt dependente, conform Ha

# ii

# Valoarea lui p-value este mai mare decat alpha = 0.01, ceea ce accepta ipoteza H0
# Putem afirma faptul ca variabilele A si B sunt independente, conform H0
```

## Exercitiul 7

<center>![](Part2/Exercise%2018.5.png)</center>

```{r, eval=FALSE}
# a

typeI.mean<-function(mu0,sigma,n,alpha,ITERATIONS=10000,test="less"){
      t.stat<-rep(NA,ITERATIONS)
      pvals<-rep(NA,ITERATIONS)
      for(i in 1:ITERATIONS){
            temporary.sample<-rnorm(n=n,mean=mu0,sd=sigma)
            temporary.mean<-mean(temporary.sample)
            temporary.sd<-sd(temporary.sample)
            t.stat[i]<-(temporary.mean-mu0)/(temporary.sd/sqrt(n))
      }
      if(test=="less"){
        pvals<-pt(t.stat,df=n-1)    
      }else 
            if(test=="greater"){
            pvals<-1-pt(t.stat,df=n-1)
      }else 
            if(test=="two.sided"){
            pvals[t.stat>=0]<-2*(1-pt(t.stat[t.stat>=0],df=n-1))
            pvals[t.stat<0]<-2*pt(t.stat[t.stat<0],df=n-1)
            
            }else {
            stop("test nu e valid. Foloseste \"less\",\"greater\",or \"two.sided\"")
      }
      return(mean(pvals<alpha))
}

# i

typeI.mean(0,1,40,0.05,test="less")
typeI.mean(0,1,40,0.05,test="greater")
typeI.mean(0,1,40,0.05,test="two.sided")

# ii

typeI.mean(-4,0.3,60,0.01,test="less")
typeI.mean(-4,0.3,60,0.01,test="greater")
typeI.mean(-4,0.3,60,0.01,test="two.sided")

# b

typeII.mean<-function(mu0,muA,sigma,n,alpha,test="two.sided",ITERATIONS=10000){
      test.t<-rep(NA,ITERATIONS)
      for(i in 1:ITERATIONS){
            temporary.sample<-rnorm(n=n,mean=muA,sd=sigma)
            temporary.mean<-mean(temporary.sample)
            temporary.sd<-sd(temporary.sample)
            test.t[i]<-(temporary.mean-mu0)/(temporary.sd/sqrt(n))
      }
      pvals<-pt(test.t,df=n-1)
      if(test=="less"){
            return(mean(pvals>=alpha))
      }else if(test=="greater"){
            return(mean(1-pvals>=alpha))
      }else if(test=="two.sided"){
            result <- pvals
            result[test.t>0] <- 1-pvals[test.t>0]
            return(mean(result>=alpha/2))
      }else {
            stop("\"test\" nu e valid. Foloseste \"less\", \"greater\" or \"two.sided\"")
      }
}

#i

typeII.mean(-3.2,-3.3,0.1,25,0.05,"two.sided")

#ii

typeII.mean(8994,5600,3888,9,0.01,"less")

#iii

typeII.mean(0.44,0.4,2.4,68,0.05,"greater")
```

## Exercitiul 8

<center>![](Part2/Exercise%2018.6.png)</center>

```{r, eval=FALSE}
# a

power.mean<-function(nvec,...){
      nlen<-length(nvec)
      result<-rep(NA,nlen)
      for(i in 1:nlen){
            result[i]<-1-typeII.mean(n=nvec[i],...)
      }
      return(result)
}

# i

sample.sizes=5:100
power.mean(nvec=50,mu0=10,muA=10.5,sigma=0.9,alpha=0.01,test="two.sided")

# ii

power.mean(nvec=44,mu0=80,muA=78.5,sigma=3.1,alpha=0.05,test="two.sided")

power.mean(nvec=44,mu0=80,muA=78.5,sigma=3.1,alpha=0.01,test="two.sided")

# b

snacks <- c(87.7,80.01,77.28,78.76,81.52,74.2,80.71,79.5,77.87,81.94,80.7,82.32,
            75.78,80.19,83.91,79.4,77.52,77.62,81.4,74.89,82.95,73.59,77.92,
            77.18,79.83,81.23,79.28,78.44,79.01,80.47,76.23,78.89,77.14,69.94,
            78.54,79.7,82.45,77.29,75.52,77.21,75.99,81.94,80.41,77.7)

sample.sizes<- 5:100

pow1 <- power.mean(
      nvec = sample.sizes,
      mu0 = 80,
      muA = 78.5,
      sigma = 3.1,
      alpha = 0.05,
      ITERATIONS = 5000,
      test = "less"
)

pow2 <- power.mean(
      nvec = sample.sizes,
      mu0 = 80,
      muA = 78.5,
      sigma = 3.1,
      alpha = 0.01,
      ITERATIONS = 5000,
      test = "less"
)

min.1<-sample.sizes[min(which(pow1>0.8))]
min.2<-sample.sizes[min(which(pow2>0.8))]

plot(sample.sizes,pow1,main="Dimensiunile minime de esantionare pentru alpha",xlab="Dimensiunea de esantionare",ylab="Putere Simulata")
points(pow2,col="lightblue")
abline(h=0.8,lty=3)
abline(v=min.1,lty=4)
abline(v=min.2,lty=4,col="lightblue")
legend("bottomright",legend=c("alpha=0.05","alpha=0.01"),fill=c("black","lightblue"))
```

## Exercitiul 9

<center>![](Part2/Exercise%2019.1.png)</center>

```{r, eval=FALSE}
info<-data.frame("dep"=c(93, 120, 65, 105, 115, 82, 99, 87, 100, 90, 78, 95, 93,
                         88, 110, 85, 45, 80, 28, 75, 70, 65, 55, 50, 40, 100, 
                         75, 65, 40, 73, 65, 50, 30, 45, 50, 45, 55, 96, 58, 95,
                         90, 65, 80, 85, 95, 82),
                 "site"=c(rep("Site i",15),
                          rep("Site ii",10),
                          rep("Site iii",12),
                          rep("Site iv",9)))
# a
infomean<-tapply(info$dep,info$site,mean)

boxplot(info$dep~info$site,
        xlab="Site",
        ylab="Depth (cm)",
        main="Boxplot pentru adancimea in cm a fiecarui sit")

# Puncte aditionale
points(1:4,infomean,pch=4)

# b
infomeancen <- info$dep-infomean[as.numeric(as.factor(info$site))]

qqnorm(infomeancen,main="Grafic QQ normal al reziduurilor")
qqline(infomeancen)

# Graficul ne ofera suficiente informatii pentru a accepta normalitatea datelor

info.sds<-tapply(info$dep,info$site,sd)
max(info.sds)/min(info.sds)

# Raportul dintre valoarea maxima si minima a variatiei standard este mai mica 
# decat 2, deci putem accepta egalitatea variatiilor

# c
infoaov<-aov(dep~site,info)
summary(infoaov)

# Valoarea lui p-value este foarte mica, deci putem respinge ipoteza H0

# d
# Verificarea celor 4 masuratori pentru aplicarea ANOVA

# 1) Sepal.Length

sepal_length.mean<-tapply(iris$Sepal.Length,iris$Species,mean)
sepal_length.meancen<-iris$Sepal.Length-sepal_length.mean[as.numeric(iris$Species)]
sepal_length.sd<-tapply(iris$Sepal.Length,iris$Species,sd)

# Verificarea variatiei

boxplot(iris$Sepal.Length~iris$Species,
        main="Boxplot pentru lungimea sepalelor pentru diferitele specii")
points(1:3,sepal_length.mean,pch=4)
max(sepal_length.sd)/min(sepal_length.sd)

# Variatia din boxplot si raportul variatiilor confirma egalitatea variatiilor

# Verificarea normalitatii

qqnorm(sepal_length.meancen)
qqline(sepal_length.meancen)

# Graficul ne ofera suficiente informatii pentru a accepta normalitatea datelor
# Se poate folosi pentru analiza variantei (ANOVA)

# 2) Sepal.width

sepal_width.mean<-tapply(iris$Sepal.Width,iris$Species,mean)
sepal_width.meancen<-iris$Sepal.Width-sepal_width.mean[as.numeric(iris$Species)]
sepal_width.sd<-tapply(iris$Sepal.Width,iris$Species,sd)

# Verificarea variatiei

boxplot(iris$Sepal.Width~iris$Species,
        main="Boxplot pentru latimea sepalelor pentru diferitele specii")
points(1:3,sepal_width.mean,pch=4)
max(sepal_width.sd)/min(sepal_width.sd)

# Variatia din boxplot si raportul variatiilor confirma egalitatea variatiilor

# Verificarea normalitatii

qqnorm(sepal_width.meancen)
qqline(sepal_width.meancen)

# Graficul ne ofera suficiente informatii pentru a accepta normalitatea datelor.
# Aceasta distribuire este mai normala decat cea de dinainte
# Se poate folosi pentru analiza variantei (ANOVA)

# 3) Petal.Length

petal_length.mean<-tapply(iris$Petal.Length,iris$Species,mean)
petal_length.meancen<-iris$Petal.Length-petal_length.mean[as.numeric(iris$Species)]
petal_length.sd<-tapply(iris$Petal.Length,iris$Species,sd)

# Verificarea variatiei

boxplot(iris$Petal.Length~iris$Species,
        main="Boxplot pentru lungimea petalelor pentru diferitele specii")
points(1:3,petal_length.mean,pch=4)
max(petal_length.sd)/min(petal_length.sd)

# Variatia din boxplot si raportul variatiilor resping egalitatea variatiilor

# Verificarea normalitatii

qqnorm(petal_length.meancen)
qqline(petal_length.meancen)

# Graficul ne ofera suficiente informatii pentru a accepta normalitatea datelor.
# Aceasta distribuire a datelor nu este potrivita pentru analiza variantei (ANOVA)

# 4) Petal.width

petal_width.mean<-tapply(iris$Petal.Width,iris$Species,mean)
petal_width.meancen<-iris$Petal.Width-petal_width.mean[as.numeric(iris$Species)]
petal_width.sd<-tapply(iris$Petal.Width,iris$Species,sd)

# Verificarea variatiei

boxplot(iris$Petal.Width~iris$Species,
        main="Boxplot pentru latimea petalelor pentru diferitele specii")
points(1:3,petal_width.mean,pch=4)
max(petal_width.sd)/min(petal_width.sd)

# Variatia din boxplot si raportul variatiilor resping egalitatea variatiilor

# Verificarea normalitatii

qqnorm(petal_width.meancen)
qqline(petal_width.meancen)

# Graficul ne ofera suficiente informatii pentru a accepta normalitatea datelor.
# Aceasta distribuire a datelor nu este potrivita pentru analiza variantei (ANOVA)

# Pentru cele mai bune rezultate, cel mai bun set de date pentru analiza variantei (ANOVA)
# Este cel dat de analiza sepalelor (Sepal.width + Sepal.length)

# e
# Generarea tabelului ANOVA folosind aov pentru Sepal.length

sepal_length.aov<-aov(Sepal.Length~Species,iris)
summary(sepal_length.aov)

# Valoarea p-valuea este mult mai mica decat F. Respingem H0

# Generarea tabelului ANOVA folosind aov pentru Sepal.width

sepal_width.aov<-aov(Sepal.Width~Species,iris)
summary(sepal_width.aov)

# Valoarea p-valuea este mult mai mica decat F. Respingem H0
```

## Exercitiul 10

<center>![](Part2/Exercise%2019.2.png)</center>

```{r, eval=FALSE}
# a

depth.f<-cut(quakes$depth,breaks=c(0,200,400,680),include.lowest = F)

# b
# Se verifica egalitatea variatiilor si normalitatea

boxplot(quakes$depth~depth.f)
depth.sd<-tapply(quakes$depth,depth.f,sd)
max(depth.sd)/min(depth.sd)

depth.mean<-tapply(quakes$depth,depth.f,mean)
depth.meancen<-quakes$depth-depth.mean[as.numeric(depth.f)]
hist(depth.meancen)
qqnorm(depth.meancen)
qqline(depth.meancen)

# Atat egalitatea variatiilor, cat si normalitatea distributiei sunt acceptate
# Ceea ce inseamna ca putem aplica testul ANOVA

# c

summary(aov(quakes$depth~depth.f))

# Valoarea foarte mica a p-value (p-value < 0.01) sugereaza ca nu toate mediile sunt egale
# Ha este ipoteza acceptata

# d

cars.mean<-aggregate(Cars93$Length,
          by=list(Airbags=Cars93$AirBags,
                  ManualTransmission=Cars93$Man.trans.avail),
          FUN=mean)
cars.mean

# e

interaction.plot(cars.mean[,1],
                 cars.mean[,2],
                 response=cars.mean[,3],
                 xlab = "Air Bags",
                 ylab="mean length",
                 trace.label = "Manual\n   Trans")

# Graficul sugereaza ca exista o interactiune intre Airbags si Manual transmission
# Considerand doar aceste doua variabile

# f

summary(aov(Length~AirBags+Man.trans.avail+AirBags:Man.trans.avail,Cars93))

# Nu sunt suficiente dovezi statistice pentru efectul interactiunii
# Dar putem confirma efectul principal al ambelor variabile asupra lungimii
```
